{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.5.1 Unsupervised Learning Capstone\n",
    "For this project you'll dig into a large amount of text and apply most of what you've covered in this unit and in the course so far.\n",
    "\n",
    "First, pick a set of texts. This can be either a series of novels, chapters, or articles. Anything you'd like. It just has to have multiple entries of varying characteristics. At least 100 should be good. There should also be at least 10 different authors, but try to keep the texts related (either all on the same topic of from the same branch of literature - something to make classification a bit more difficult than obviously different subjects).\n",
    "\n",
    "This capstone can be an extension of your NLP challenge if you wish to use the same corpus. If you found problems with that data set that limited your analysis, however, it may be worth using what you learned to choose a new corpus. Reserve 25% of your corpus as a test set.\n",
    "\n",
    "The first technique is to create a series of clusters. Try several techniques and pick the one you think best represents your data. Make sure there is a narrative and reasoning around why you have chosen the given clusters. Are authors consistently grouped into the same cluster?\n",
    "\n",
    "Next, perform some unsupervised feature generation and selection using the techniques covered in this unit and elsewhere in the course. Using those features then build models to attempt to classify your texts by author. Try different permutations of unsupervised and supervised techniques to see which combinations have the best performance.\n",
    "\n",
    "Lastly return to your holdout group. Does your clustering on those members perform as you'd expect? Have your clusters remained stable or changed dramatically? What about your model? Is it's performance consistent?\n",
    "\n",
    "If there is a divergence in the relative stability of your model and your clusters, delve into why.\n",
    "\n",
    "Your end result should be a write up of how clustering and modeling compare for classifying your texts. What are the advantages of each? Why would you want to use one over the other? Approximately 3-5 pages is a good length for your write up, and remember to include visuals to help tell your story!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Necessary imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import requests\n",
    "import re\n",
    "import spacy\n",
    "from collections import Counter\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import os\n",
    "import warnings\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "The goal of this project is to train a model with texts from different authors, and determine the accuracy of the model when predicting from which author a new text belongs. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Selection and Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I selected 10 literary works from these 12 different authors:\n",
    "\n",
    "- emerson\n",
    "- shakespeare\n",
    "- hawthorne\n",
    "- kant\n",
    "- poe\n",
    "- burroughs\n",
    "- doyle\n",
    "- plato\n",
    "- dickens\n",
    "- aristotle\n",
    "- jefferson\n",
    "- irving \n",
    "\n",
    "I downloaded the .txt files from:\n",
    "\n",
    "http://www.textfiles.com/etext/AUTHORS/\n",
    "\n",
    "And manually cleaned the metadata from each text. Running the scripts below with their complete work required too much memory that my computer couldn't handle, so I manually cutted off from each file a part of the texts randomnly, and used this to persue my goal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Each file is named \"author-work.txt\"\n",
    "\n",
    "filenames = os.listdir('../Unsupervised capstone/books/') \n",
    "authors = list(set([filename.split('-')[0] for filename in filenames]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['doyle',\n",
       " 'poe',\n",
       " 'emerson',\n",
       " 'shakespeare',\n",
       " 'dickens',\n",
       " 'hawthorne',\n",
       " 'aristotle',\n",
       " 'burroughs',\n",
       " 'jefferson',\n",
       " 'irving',\n",
       " 'plato',\n",
       " 'kant']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "authors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plato</td>\n",
       "      <td>cratylus</td>\n",
       "      <td>plato-cratylus-338.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kant</td>\n",
       "      <td>science</td>\n",
       "      <td>kant-science-146.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jefferson</td>\n",
       "      <td>public</td>\n",
       "      <td>jefferson-public-259.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plato</td>\n",
       "      <td>critias</td>\n",
       "      <td>plato-critias-339.txt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irving</td>\n",
       "      <td>broken</td>\n",
       "      <td>irving-broken-571.txt</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author     title                  filename\n",
       "0      plato  cratylus    plato-cratylus-338.txt\n",
       "1       kant   science      kant-science-146.txt\n",
       "2  jefferson    public  jefferson-public-259.txt\n",
       "3      plato   critias     plato-critias-339.txt\n",
       "4     irving    broken     irving-broken-571.txt"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame(columns = ['author', 'title', 'filename'])\n",
    "\n",
    "df['filename'] = filenames\n",
    "df['author'] = [file.split('-')[0] for file in df['filename']]\n",
    "df['title'] = [file.split('-')[1].split('.txt')[0] for file in df['filename']]\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad files encountered: 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plato</td>\n",
       "      <td>cratylus</td>\n",
       "      <td>plato-cratylus-338.txt</td>\n",
       "      <td>Her. I should explain to you, Socrates, that...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kant</td>\n",
       "      <td>science</td>\n",
       "      <td>kant-science-146.txt</td>\n",
       "      <td>\\n  This question may be said to be about as e...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jefferson</td>\n",
       "      <td>public</td>\n",
       "      <td>jefferson-public-259.txt</td>\n",
       "      <td>\\n        THAT _it is the opinion of this Comm...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plato</td>\n",
       "      <td>critias</td>\n",
       "      <td>plato-critias-339.txt</td>\n",
       "      <td>Timaeus. How thankful I am, Socrates, that I h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irving</td>\n",
       "      <td>broken</td>\n",
       "      <td>irving-broken-571.txt</td>\n",
       "      <td>\\n  IT IS a common practice with those who hav...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author     title                  filename  \\\n",
       "0      plato  cratylus    plato-cratylus-338.txt   \n",
       "1       kant   science      kant-science-146.txt   \n",
       "2  jefferson    public  jefferson-public-259.txt   \n",
       "3      plato   critias     plato-critias-339.txt   \n",
       "4     irving    broken     irving-broken-571.txt   \n",
       "\n",
       "                                           full_text  \n",
       "0    Her. I should explain to you, Socrates, that...  \n",
       "1  \\n  This question may be said to be about as e...  \n",
       "2  \\n        THAT _it is the opinion of this Comm...  \n",
       "3  Timaeus. How thankful I am, Socrates, that I h...  \n",
       "4  \\n  IT IS a common practice with those who hav...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text'] = None\n",
    "texts = []\n",
    "bad_file_count = 0\n",
    "for i, filename in enumerate(filenames):\n",
    "    try:\n",
    "        with open(r'../Unsupervised capstone/books/'+filename, encoding='utf-8') as file:\n",
    "            data = file.read()\n",
    "            df.loc[i, 'full_text'] = data\n",
    "            texts.append(data)\n",
    "    except:\n",
    "        bad_file_count += 1\n",
    "\n",
    "df.dropna(inplace=True)\n",
    "df.reset_index(inplace=True, drop=True)\n",
    "print('Number of bad files encountered:', bad_file_count)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        Her. I should explain to you, Socrates, that...\n",
       "1      \\n  This question may be said to be about as e...\n",
       "2      \\n        THAT _it is the opinion of this Comm...\n",
       "3      Timaeus. How thankful I am, Socrates, that I h...\n",
       "4      \\n  IT IS a common practice with those who hav...\n",
       "5                            \\n                      ...\n",
       "6      \\n\\n  Soc. He whom you mean, Crito, is Euthyde...\n",
       "7      \\n  MISERY is manifold. The wretchedness of ea...\n",
       "8      \\n\\n  Soc. I often envy the profession of a rh...\n",
       "9      \\n\"Magnifique!\" ejaculated the Countess de Cou...\n",
       "10     \\n        Resolved, that it be an instruction ...\n",
       "11     \\n  The dinner was served up in the great hall...\n",
       "12                                                   ...\n",
       "13     \\n\\n  Charmides, he replied, is his name; he i...\n",
       "14              \\n                                 1\\...\n",
       "15     \\n        BROTHER JOHN BAPTIST DE COIGNE, -- I...\n",
       "16     \\n  There are not many people -- and as it is ...\n",
       "17     \\n\\n        Limits\\n        Virginia is bounde...\n",
       "18     \\n        It chanced during one winter, a few ...\n",
       "19     \\n\\n        I have been twice in England.  In ...\n",
       "20         \\n\\n  \"Hopkins has called me in seven time...\n",
       "21     \\n   \"O, some drunken man, I suppose,\" answere...\n",
       "22     \\n        There is one mind common to all indi...\n",
       "23     \\n        In this refulgent summer, it has bee...\n",
       "24     \\n                                   1\\n\\n    ...\n",
       "25     \\n\\n  Ath. Yes, and a noble reputation it was,...\n",
       "26     \\n  WE have, in the next place, to treat of Me...\n",
       "27     \\n\\n  FOR the most wild, yet most homely narra...\n",
       "28     \\n  Lys. You have seen the exhibition of the m...\n",
       "29     \\n\\n  His career has been a long one -- though...\n",
       "                             ...                        \n",
       "72     \\n\\n  THERE are few places more favorable to t...\n",
       "73     \\n\\n\\n     Once upon a time -- of all the good...\n",
       "74     \\n  This work is called the Critique of Practi...\n",
       "75     \\n\\nKING HENRY\\tthe Fifth. (KING HENRY V)\\n\\nD...\n",
       "76     \\n        I am an officer lately returned from...\n",
       "77     \\n\\nLieutenant Albert Werper had only the pres...\n",
       "78     \\ncharacters and manners. Even when a mere chi...\n",
       "79     \\n\\n  To Sherlock Holmes she is always the wom...\n",
       "80     \\nThere is a very pleasant and commodious libr...\n",
       "81                                         \\n        ...\n",
       "82     \\n\\n  Cr. And yet other old men find themselve...\n",
       "83     \\n\\tLive register'd upon our brazen tombs\\n\\tA...\n",
       "84     \\n\"The entire affair is shrouded in mystery,\" ...\n",
       "85     \\nNORFOLK\\tI thank your grace,\\n\\tHealthful; a...\n",
       "86     \\n\\nMr. Hungerton, her father, really was the ...\n",
       "87     \\n  Ancient Greek philosophy was divided into ...\n",
       "88     \\n  Sherlock Holmes took his bottle from the c...\n",
       "89     \\t\\nKING JOHN\\tBear mine to him, and so depart...\n",
       "90     \\n   AN ELDERLY MAN, with his pretty daughter ...\n",
       "91     \\nI am a very old man; how old I do not know. ...\n",
       "92     \\n\\nIN THE FIRST PLACE PLEASE BEAR IN MIND THA...\n",
       "93     \\t\\nESCALUS\\tTroth, and your bum is the greate...\n",
       "94     \\n\\n     These Prolegomena are destined for th...\n",
       "95     \\n\\n  NOTHING in England exercises a more deli...\n",
       "96     \\n   NOT A GREAT WHILE AGO, passing through th...\n",
       "97     \\n\\n  IT WAS a brilliant moonlight night, but ...\n",
       "98     \\n\\n        The tradition in my father's famil...\n",
       "99     \\nit comes to pass that so many heads, on whic...\n",
       "100    \\n  IT IS a pious custom, in some Catholic cou...\n",
       "101    \\n\\nThe long boat of the Marjorie W. was float...\n",
       "Name: full_text, Length: 102, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def text_cleaner(text):\n",
    "    text = re.sub(r'--', ' ', text)\n",
    "    text = re.sub(r'\\d', '', text)\n",
    "    #text = re.sub(r'\\.', ' ', text)\n",
    "    text = re.sub(r'\\,', '', text)\n",
    "    text = re.sub(r'\\_', '', text)\n",
    "    text = re.sub(r'\\\"', '', text)\n",
    "    text = re.sub(r'\\!', '', text)\n",
    "    text = re.sub(r'\\?', '', text)\n",
    "    text = text.lower()\n",
    "    text = ' '.join(text.split())\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>author</th>\n",
       "      <th>title</th>\n",
       "      <th>filename</th>\n",
       "      <th>full_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>plato</td>\n",
       "      <td>cratylus</td>\n",
       "      <td>plato-cratylus-338.txt</td>\n",
       "      <td>her. i should explain to you socrates that our...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kant</td>\n",
       "      <td>science</td>\n",
       "      <td>kant-science-146.txt</td>\n",
       "      <td>this question may be said to be about as embar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>jefferson</td>\n",
       "      <td>public</td>\n",
       "      <td>jefferson-public-259.txt</td>\n",
       "      <td>that it is the opinion of this committee that ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>plato</td>\n",
       "      <td>critias</td>\n",
       "      <td>plato-critias-339.txt</td>\n",
       "      <td>timaeus. how thankful i am socrates that i hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>irving</td>\n",
       "      <td>broken</td>\n",
       "      <td>irving-broken-571.txt</td>\n",
       "      <td>it is a common practice with those who have ou...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      author     title                  filename  \\\n",
       "0      plato  cratylus    plato-cratylus-338.txt   \n",
       "1       kant   science      kant-science-146.txt   \n",
       "2  jefferson    public  jefferson-public-259.txt   \n",
       "3      plato   critias     plato-critias-339.txt   \n",
       "4     irving    broken     irving-broken-571.txt   \n",
       "\n",
       "                                           full_text  \n",
       "0  her. i should explain to you socrates that our...  \n",
       "1  this question may be said to be about as embar...  \n",
       "2  that it is the opinion of this committee that ...  \n",
       "3  timaeus. how thankful i am socrates that i hav...  \n",
       "4  it is a common practice with those who have ou...  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataframe shape:  (102, 4)\n"
     ]
    }
   ],
   "source": [
    "# Clean all lead paragraphs\n",
    "df['full_text'] = df.full_text.map(lambda x: text_cleaner(str(x)))\n",
    "display(df.head())\n",
    "print('Dataframe shape: ', df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      her. i should explain to you socrates that our...\n",
       "1      this question may be said to be about as embar...\n",
       "2      that it is the opinion of this committee that ...\n",
       "3      timaeus. how thankful i am socrates that i hav...\n",
       "4      it is a common practice with those who have ou...\n",
       "5      every art and every inquiry and similarly ever...\n",
       "6      soc. he whom you mean crito is euthydemus; and...\n",
       "7      misery is manifold. the wretchedness of earth ...\n",
       "8      soc. i often envy the profession of a rhapsode...\n",
       "9      magnifique ejaculated the countess de coude be...\n",
       "10     resolved that it be an instruction to the said...\n",
       "11     the dinner was served up in the great hall whe...\n",
       "12     our next task is to study coming-to-be and pas...\n",
       "13     charmides he replied is his name; he is my cou...\n",
       "14     we must in the next place investigate the subj...\n",
       "15     brother john baptist de coigne i am very much ...\n",
       "16     there are not many people and as it is desirab...\n",
       "17     limits virginia is bounded on the east by the ...\n",
       "18     it chanced during one winter a few years ago t...\n",
       "19     i have been twice in england. in on my return ...\n",
       "20     hopkins has called me in seven times and on ea...\n",
       "21     o some drunken man i suppose answered the lime...\n",
       "22     there is one mind common to all individual men...\n",
       "23     in this refulgent summer it has been a luxury ...\n",
       "24     all men by nature desire to know. an indicatio...\n",
       "25     ath. yes and a noble reputation it was worthy ...\n",
       "26     we have in the next place to treat of memory a...\n",
       "27     for the most wild yet most homely narrative wh...\n",
       "28     lys. you have seen the exhibition of the man f...\n",
       "29     his career has been a long one though it is po...\n",
       "                             ...                        \n",
       "72     there are few places more favorable to the stu...\n",
       "73     once upon a time of all the good days in the y...\n",
       "74     this work is called the critique of practical ...\n",
       "75     king henry the fifth. (king henry v) duke of g...\n",
       "76     i am an officer lately returned from service &...\n",
       "77     lieutenant albert werper had only the prestige...\n",
       "78     characters and manners. even when a mere child...\n",
       "79     to sherlock holmes she is always the woman. i ...\n",
       "80     there is a very pleasant and commodious librar...\n",
       "81     of the parts of animals some are simple: to wi...\n",
       "82     cr. and yet other old men find themselves in s...\n",
       "83     live register'd upon our brazen tombs and then...\n",
       "84     the entire affair is shrouded in mystery said ...\n",
       "85     norfolk i thank your grace healthful; and ever...\n",
       "86     mr. hungerton her father really was the most t...\n",
       "87     ancient greek philosophy was divided into thre...\n",
       "88     sherlock holmes took his bottle from the corne...\n",
       "89     king john bear mine to him and so depart in pe...\n",
       "90     an elderly man with his pretty daughter on his...\n",
       "91     i am a very old man; how old i do not know. po...\n",
       "92     in the first place please bear in mind that i ...\n",
       "93     escalus troth and your bum is the greatest thi...\n",
       "94     these prolegomena are destined for the use not...\n",
       "95     nothing in england exercises a more delightful...\n",
       "96     not a great while ago passing through the gate...\n",
       "97     it was a brilliant moonlight night but extreme...\n",
       "98     the tradition in my father's family was that t...\n",
       "99     it comes to pass that so many heads on which n...\n",
       "100    it is a pious custom in some catholic countrie...\n",
       "101    the long boat of the marjorie w. was floating ...\n",
       "Name: full_text, Length: 102, dtype: object"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['full_text']\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Input, Output & Holdout"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting into training and testing sets:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifying variables\n",
    "X = df['full_text']\n",
    "y = df['author']\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Generation \n",
    "### Tf-idf Vectorization\n",
    "To obtain better cluster results we will vectorize the words in our texts.  Term Frequency Inverse Document Frequency (Tf-idf) is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.  The tf-idf value increases proportionally to the number of times a word appears in the document and is offset by the frequency of the word in the corpus, which helps to adjust for the fact that some words appear more frequently in general."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features: 882\n",
      "Original sentence: that it is the opinion of this committee that when the general council and assembly or general court of any of his majesty's provinces or colonies in america shall propose to make provision according to the condition circumstance or situation of such province or colony for contributing their proportion to the common defence (such proportion to be raised under the authority of the general court or general assembly of such province or colony and disposable by parliament) and shall engage to make provision also for the support of the civil government and the administration of justice in such province or colony it will be proper if such proposal shall be approved by his majesty and the two houses of parliament; and for so long as such provision shall be made accordingly to forbear in respect of such province or colony to lay any duty tax or assessment or to impose any further duty tax or assessment except only such duties as it may be expedient to continue to levy or impose for the regulation of commerce the net produce of the duties last mentioned to be carried to the account of such province or colony respectively. the congress took the said resolution into consideration and are thereupon of opinion: that the colonies of america are entitled to the sole and exclusive privilege of giving and granting their own money; that this involves a right of deliberating whether they will make any gift for what purposes it shall be made and what shall be it's amount; and that it is a high breach of this privilege for any body of men extraneous to their constitutions to prescribe the purposes for which money shall be levied on them to take to themselves the authority of judging of their conditions circumstances and situations; and of determining the amount of the contribution to be levied.\n",
      "Tf_idf vector: {'quiet': 0.060674195379106864, 'lie': 0.060674195379106864, 'french': 0.055602467188527308, 'assume': 0.060674195379106864, 'ill': 0.055602467188527308, 'dead': 0.051814343438969478, 'help': 0.060674195379106864, 'quarrel': 0.18202258613732059, 'proud': 0.057926018029832056, 'mankind': 0.060674195379106864, 'committed': 0.057926018029832056, 'forever': 0.060674195379106864, 'france': 0.057926018029832056, 'king': 0.053589715898549273, 'father': 0.047478041307686701, 'lost': 0.050226218656961509, 'felt': 0.047478041307686701, 'began': 0.10362868687793896, 'weak': 0.057926018029832056, 'came': 0.079556483869632308, 'smoke': 0.053589715898549273, 'custom': 0.060674195379106864, 'walls': 0.060674195379106864, 'hanging': 0.060674195379106864, 'represented': 0.060674195379106864, 'attended': 0.060674195379106864, 'value': 0.057926018029832056, 'disposition': 0.060674195379106864, 'return': 0.051814343438969478, 'happened': 0.060674195379106864, 'particularly': 0.18202258613732059, 'john': 0.055602467188527308, 'engaged': 0.057926018029832056, 'grown': 0.053589715898549273, 'english': 0.37982433046149361, 'did': 0.03641474469322839, 'determined': 0.046271538028145091, 'strong': 0.13881461408443527, 'held': 0.055602467188527308, 'carry': 0.057926018029832056, 'pleased': 0.057926018029832056, 'blood': 0.051814343438969478, 'inhabitants': 0.057926018029832056, 'assembled': 0.060674195379106864, 'settled': 0.060674195379106864, 'young': 0.039042815875519374, 'hearing': 0.055602467188527308, 'opportunity': 0.057926018029832056, 'unless': 0.051814343438969478, 'exist': 0.057926018029832056, 'land': 0.20725737375587791, 'family': 0.050226218656961509, 'born': 0.050226218656961509, 'stand': 0.053589715898549273, 'fight': 0.057926018029832056, 'brothers': 0.060674195379106864, 'knew': 0.050226218656961509, 'years': 0.037030064585541353, 'wisdom': 0.051814343438969478, 'brother': 0.23170407211932822, 'hand': 0.043141739176403918, 'left': 0.042227929446967682, 'way': 0.037671576046919363, 'health': 0.057926018029832056, 'parts': 0.04411454406609893, 'treat': 0.055602467188527308, 'love': 0.13546347139914586, 'life': 0.032693762454258569, 'hope': 0.090308980932763891, 'little': 0.03177995272482232, 'discourse': 0.060674195379106864, 'knowing': 0.055602467188527308, 'things': 0.039778241934816154, 'consider': 0.047478041307686701, 'assistance': 0.060674195379106864, 'having': 0.047478041307686701, 'speak': 0.048789585041609233, 'set': 0.042227929446967682, 'long': 0.13882605497694636, 'support': 0.060674195379106864, 'respect': 0.051814343438969478, 'nation': 0.18202258613732059, 'war': 0.39031668033287387, 'people': 0.040551398287165967, 'power': 0.041366366716824129, 'nations': 0.11585203605966411, 'peace': 0.048789585041609233, 'act': 0.051814343438969478, 'free': 0.16680740156558191, 'wish': 0.2590717171948474, 'like': 0.082664678259273011, 'reason': 0.03641474469322839, 'general': 0.037030064585541353, 'country': 0.11502482495839163, 'shall': 0.061836779989357549, 'given': 0.088229088132197861, 'old': 0.058660530425341612, 'right': 0.11301472814075808, 'better': 0.082732733433648259, 'say': 0.059423773430274322, 'great': 0.084720474658980138, 'son': 0.050226218656961509, 'good': 0.12041368626008243, 'explanation': 0.055602467188527308, 'true': 0.038341608319463878, 'men': 0.028594839153374019, 'friend': 0.12165419486149789}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "vectorizer = TfidfVectorizer(min_df=4,\n",
    "                            stop_words='english',\n",
    "                            lowercase=False,\n",
    "                            use_idf=True,\n",
    "                            norm=u'l2')\n",
    "# Applying the vectorizer\n",
    "X_tfidf = vectorizer.fit_transform(X)\n",
    "print('Number of features: {}'.format(X_tfidf.get_shape()[1]))\n",
    "\n",
    "# Splitting into train and test sets\n",
    "X_train_tfidf, X_test_tfidf, y_train, y_test = train_test_split(X_tfidf, y, test_size=0.25, random_state=42)\n",
    "\n",
    "# Reshape vectorizer to readable content\n",
    "X_train_tfidf_csr = X_train_tfidf.tocsr()\n",
    "\n",
    "# Number of paragraphs\n",
    "n = X_train_tfidf_csr.shape[0]\n",
    "\n",
    "# A list of dictionaries, one per paragraph\n",
    "tfidf_bypara = [{} for _ in range(0,n)]\n",
    "\n",
    "# List of features\n",
    "terms = vectorizer.get_feature_names()\n",
    "\n",
    "# For each paragraph, lists the feature words and their tf-idf scores\n",
    "for i, j in zip(*X_train_tfidf_csr.nonzero()):\n",
    "    tfidf_bypara[i][terms[j]] = X_train_tfidf_csr[i, j]\n",
    "\n",
    "# Keep in mind that the log base 2 of 1 is 0, so a tf-idf score of 0 indicates that the word was present once in that sentence.\n",
    "print('Original sentence:', X_train[2])\n",
    "print('Tf_idf vector:', tfidf_bypara[0])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now normalize our data to best cluster data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "X_norm = normalize(X_train_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Natural Language Processing - spaCy\n",
    "We will tokenize each sentence to be able to extract information and add as features in our models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiating spaCy\n",
    "nlp = spacy.load('en')\n",
    "X_train_words = []\n",
    "\n",
    "for row in X_train:\n",
    "    # Processing each row for tokens\n",
    "    row_doc = nlp(row)\n",
    "    # Calculating length of each sentence\n",
    "    sent_len = len(row_doc) \n",
    "    # Initializing counts\n",
    "    advs = 0\n",
    "    verb = 0\n",
    "    noun = 0\n",
    "    adj = 0\n",
    "    for token in row_doc:\n",
    "        # Identifying each part and adding to counts\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj +=1\n",
    "    # Creating a list of all features for each sentence\n",
    "    X_train_words.append([row_doc, advs, verb, noun, adj, sent_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train_new = y_train.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Joining the new features and the author names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>author</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(brother, john, baptist, de, coigne, i, am, ve...</td>\n",
       "      <td>53</td>\n",
       "      <td>184</td>\n",
       "      <td>125</td>\n",
       "      <td>82</td>\n",
       "      <td>845</td>\n",
       "      <td>jefferson</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(once, upon, a, time, of, all, the, good, days...</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>296</td>\n",
       "      <td>dickens</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(soc, ., very, good, callicles, ;, but, will, ...</td>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>275</td>\n",
       "      <td>plato</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(magnifique, ejaculated, the, countess, de, co...</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>263</td>\n",
       "      <td>burroughs</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(the, entire, affair, is, shrouded, in, myster...</td>\n",
       "      <td>24</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>43</td>\n",
       "      <td>392</td>\n",
       "      <td>burroughs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "0  (brother, john, baptist, de, coigne, i, am, ve...   53   184   125   82   \n",
       "1  (once, upon, a, time, of, all, the, good, days...   22    54    62   37   \n",
       "2  (soc, ., very, good, callicles, ;, but, will, ...   19    69    49   17   \n",
       "3  (magnifique, ejaculated, the, countess, de, co...   27    49    51   37   \n",
       "4  (the, entire, affair, is, shrouded, in, myster...   24    71    88   43   \n",
       "\n",
       "   sent_length     author  \n",
       "0          845  jefferson  \n",
       "1          296    dickens  \n",
       "2          275      plato  \n",
       "3          263  burroughs  \n",
       "4          392  burroughs  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Data frame for features\n",
    "txt_bow = pd.DataFrame(data=X_train_words, columns=['BOW', 'ADV', 'VERB', 'NOUN', 'ADJ', 'sent_length'])\n",
    "\n",
    "# Adding author data\n",
    "txt_bow = pd.concat([txt_bow, y_train_new], ignore_index=False, axis=1)\n",
    "txt_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>BOW</th>\n",
       "      <th>ADV</th>\n",
       "      <th>VERB</th>\n",
       "      <th>NOUN</th>\n",
       "      <th>ADJ</th>\n",
       "      <th>sent_length</th>\n",
       "      <th>author</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>...</th>\n",
       "      <th>872</th>\n",
       "      <th>873</th>\n",
       "      <th>874</th>\n",
       "      <th>875</th>\n",
       "      <th>876</th>\n",
       "      <th>877</th>\n",
       "      <th>878</th>\n",
       "      <th>879</th>\n",
       "      <th>880</th>\n",
       "      <th>881</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>(brother, john, baptist, de, coigne, i, am, ve...</td>\n",
       "      <td>53</td>\n",
       "      <td>184</td>\n",
       "      <td>125</td>\n",
       "      <td>82</td>\n",
       "      <td>845</td>\n",
       "      <td>jefferson</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.037030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.039043</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>(once, upon, a, time, of, all, the, good, days...</td>\n",
       "      <td>22</td>\n",
       "      <td>54</td>\n",
       "      <td>62</td>\n",
       "      <td>37</td>\n",
       "      <td>296</td>\n",
       "      <td>dickens</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.118679</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>(soc, ., very, good, callicles, ;, but, will, ...</td>\n",
       "      <td>19</td>\n",
       "      <td>69</td>\n",
       "      <td>49</td>\n",
       "      <td>17</td>\n",
       "      <td>275</td>\n",
       "      <td>plato</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.072124</td>\n",
       "      <td>0.104377</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>(magnifique, ejaculated, the, countess, de, co...</td>\n",
       "      <td>27</td>\n",
       "      <td>49</td>\n",
       "      <td>51</td>\n",
       "      <td>37</td>\n",
       "      <td>263</td>\n",
       "      <td>burroughs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.287463</td>\n",
       "      <td>0.290630</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>(the, entire, affair, is, shrouded, in, myster...</td>\n",
       "      <td>24</td>\n",
       "      <td>71</td>\n",
       "      <td>88</td>\n",
       "      <td>43</td>\n",
       "      <td>392</td>\n",
       "      <td>burroughs</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 889 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 BOW  ADV  VERB  NOUN  ADJ  \\\n",
       "0  (brother, john, baptist, de, coigne, i, am, ve...   53   184   125   82   \n",
       "1  (once, upon, a, time, of, all, the, good, days...   22    54    62   37   \n",
       "2  (soc, ., very, good, callicles, ;, but, will, ...   19    69    49   17   \n",
       "3  (magnifique, ejaculated, the, countess, de, co...   27    49    51   37   \n",
       "4  (the, entire, affair, is, shrouded, in, myster...   24    71    88   43   \n",
       "\n",
       "   sent_length     author    0    1    2 ...   872  873  874       875  \\\n",
       "0          845  jefferson  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.000000   \n",
       "1          296    dickens  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.118679   \n",
       "2          275      plato  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.000000   \n",
       "3          263  burroughs  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.000000   \n",
       "4          392  burroughs  0.0  0.0  0.0 ...   0.0  0.0  0.0  0.000000   \n",
       "\n",
       "        876       877  878       879       880  881  \n",
       "0  0.037030  0.000000  0.0  0.000000  0.039043  0.0  \n",
       "1  0.000000  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "2  0.072124  0.104377  0.0  0.000000  0.000000  0.0  \n",
       "3  0.000000  0.000000  0.0  0.287463  0.290630  0.0  \n",
       "4  0.000000  0.000000  0.0  0.000000  0.000000  0.0  \n",
       "\n",
       "[5 rows x 889 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_norm_df = pd.DataFrame(data=X_norm.toarray())\n",
    "txt_tfidf_bow = pd.concat([txt_bow, X_norm_df], ignore_index=False, axis=1)\n",
    "txt_tfidf_bow.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final training dataframe shape: (76, 889)\n"
     ]
    }
   ],
   "source": [
    "print('Final training dataframe shape:', txt_tfidf_bow.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection\n",
    "Using SelectKBest, we selected the best 150 features:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Identifying features and labels to choose from\n",
    "features = txt_tfidf_bow.drop(['BOW', 'author'], axis=1)\n",
    "y2_train = txt_tfidf_bow.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "# Instantiating and fitting the 150 best features\n",
    "kbest = SelectKBest(chi2, k=150)\n",
    "X2_train = kbest.fit_transform(features, y2_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Means Clustering\n",
    "K-means clustering aims to partition n observations into k clusters in which each observation belongs to the cluster with the nearest mean, serving as a prototype of the cluster. This results in a partitioning of the data space into Voronoi cells (Wikipedia info)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22a4695358>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "from  scipy.spatial.distance  import cdist\n",
    "# Use the elbow method to see what is the optimal amount of clusters.\n",
    "\n",
    "# k means determine k\n",
    "distortions = []\n",
    "K = range(1,20)\n",
    "for k in K:\n",
    "    kmeanModel = KMeans(n_clusters=k).fit(X2_train)\n",
    "    kmeanModel.fit(X2_train)\n",
    "    distortions.append(sum(np.min(cdist(X2_train, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) / X2_train.shape[0])\n",
    "\n",
    "# Plot the elbow\n",
    "sns.set_style('darkgrid')\n",
    "plt.plot(K, distortions, 'bx-')\n",
    "plt.xlabel('k')\n",
    "plt.ylabel('Distortion')\n",
    "plt.title('The Elbow Method showing the optimal k')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aristotle</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burroughs</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doyle</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerson</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawthorne</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irving</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jefferson</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kant</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plato</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poe</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0  1  2  3  4\n",
       "author                    \n",
       "aristotle    2  1  2  0  2\n",
       "burroughs    7  0  2  0  0\n",
       "dickens      3  0  2  0  1\n",
       "doyle        3  0  3  0  1\n",
       "emerson      2  0  5  0  0\n",
       "hawthorne    6  0  2  0  0\n",
       "irving       2  0  4  0  0\n",
       "jefferson    2  0  2  0  1\n",
       "kant         3  1  1  0  0\n",
       "plato        4  0  3  0  2\n",
       "poe          1  0  1  0  0\n",
       "shakespeare  3  1  0  1  0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calulate predicted values\n",
    "kmeans = KMeans(n_clusters=5, init='k-means++', random_state=42, n_init=20)\n",
    "y_pred = kmeans.fit_predict(X2_train)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make it easier to visualize our potential clusters, we will reduce the data to 2 components using PCA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f22b17e1668>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Reduce it to two components.\n",
    "X_pca = PCA(2).fit_transform(X2_train)\n",
    "\n",
    "# Calculate predicted values.\n",
    "y_pred = KMeans(n_clusters=5, random_state=42).fit_predict(X_pca)\n",
    "\n",
    "# Plot the solution.\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1], c=y_pred, s=50)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.5006142\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import silhouette_score\n",
    "\n",
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X_pca, y_pred, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The silhouette score did much beter than what I expected."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mini Batch K Means"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aristotle</th>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burroughs</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doyle</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerson</th>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawthorne</th>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irving</th>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jefferson</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kant</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plato</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poe</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0  1  2  3  4\n",
       "author                    \n",
       "aristotle    3  2  0  1  1\n",
       "burroughs    0  4  0  5  0\n",
       "dickens      1  2  0  3  0\n",
       "doyle        0  1  0  3  3\n",
       "emerson      0  6  0  0  1\n",
       "hawthorne    0  5  0  2  1\n",
       "irving       0  4  0  1  1\n",
       "jefferson    1  2  0  2  0\n",
       "kant         0  2  1  2  0\n",
       "plato        1  2  0  3  3\n",
       "poe          0  2  0  0  0\n",
       "shakespeare  0  1  2  2  0"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import MiniBatchKMeans\n",
    "minikmeans = MiniBatchKMeans(n_clusters=5, init='k-means++', random_state=42, init_size=1000, batch_size=1000)\n",
    "\n",
    "y_pred2 = minikmeans.fit_predict(X_pca)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.4524854\n"
     ]
    }
   ],
   "source": [
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X_pca, y_pred2, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It obtained a similar performance to the K-Means Clustering\n",
    "\n",
    "### Spectral Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/manifold/spectral_embedding_.py:234: UserWarning: Graph is not fully connected, spectral embedding may not work as expected.\n",
      "  warnings.warn(\"Graph is not fully connected, spectral embedding\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aristotle</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burroughs</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doyle</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerson</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawthorne</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irving</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jefferson</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kant</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plato</th>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poe</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0   1   2   3   4   5   6   7   8   9   10  11\n",
       "author                                                     \n",
       "aristotle     6   0   1   0   0   0   0   0   0   0   0   0\n",
       "burroughs     7   0   0   1   0   0   0   0   0   0   0   1\n",
       "dickens       5   0   0   0   0   1   0   0   0   0   0   0\n",
       "doyle         6   0   0   0   0   1   0   0   0   0   0   0\n",
       "emerson       5   0   0   0   1   0   0   0   1   0   0   0\n",
       "hawthorne     5   0   0   0   0   0   1   1   0   0   1   0\n",
       "irving        5   0   0   0   1   0   0   0   0   0   0   0\n",
       "jefferson     3   0   0   1   0   0   0   0   0   0   0   1\n",
       "kant          3   1   0   0   0   0   0   0   0   0   1   0\n",
       "plato         8   0   0   0   0   0   0   0   0   1   0   0\n",
       "poe           1   1   0   0   0   0   0   0   0   0   0   0\n",
       "shakespeare   4   0   0   0   0   0   0   0   0   1   0   0"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import SpectralClustering\n",
    "\n",
    "n_clusters= 12\n",
    "sc = SpectralClustering(n_clusters=n_clusters)\n",
    "y_pred3 = sc.fit_predict(X_pca)\n",
    "\n",
    "pd.crosstab(y2_train, y_pred3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: -0.3757289\n"
     ]
    }
   ],
   "source": [
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X_pca, y_pred3, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model didn't perform correctly.\n",
    "\n",
    "### Affinity Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of estimated clusters: 10\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aristotle</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>burroughs</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doyle</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerson</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawthorne</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irving</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jefferson</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kant</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plato</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poe</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0  1  2  3  4  5  6  7  8  9\n",
       "author                                   \n",
       "aristotle    0  0  1  1  0  0  2  2  1  0\n",
       "burroughs    3  0  0  0  3  0  0  3  0  0\n",
       "dickens      1  0  0  1  2  0  1  1  0  0\n",
       "doyle        1  0  2  1  3  0  0  0  0  0\n",
       "emerson      2  0  0  3  0  0  0  2  0  0\n",
       "hawthorne    1  0  0  1  0  0  0  6  0  0\n",
       "irving       2  0  1  1  0  0  0  2  0  0\n",
       "jefferson    1  1  0  1  1  0  0  1  0  0\n",
       "kant         1  0  0  0  1  0  0  2  0  1\n",
       "plato        1  1  2  1  2  0  0  2  0  0\n",
       "poe          1  0  0  0  0  0  0  1  0  0\n",
       "shakespeare  0  0  0  0  1  1  0  2  0  1"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.cluster import AffinityPropagation\n",
    "\n",
    "af = AffinityPropagation(damping=0.5, max_iter=550, copy=False)\n",
    "y_pred4 = af.fit_predict(X_pca)\n",
    "\n",
    "cluster_centers_indices = af.cluster_centers_indices_\n",
    "n_clusters = len(cluster_centers_indices)\n",
    "print('Number of estimated clusters: {}'.format(n_clusters))\n",
    "\n",
    "pd.crosstab(y2_train, y_pred4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.4256587\n"
     ]
    }
   ],
   "source": [
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X_pca, y_pred4, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Affinity Propagation, didn't perform very well, hence I will use the k-means clusters as additional features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_train_c = pd.DataFrame(X_pca)\n",
    "X2_train_c['kmeans_clust'] = y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Latent Semantic Analysis\n",
    "\n",
    "We will now use LSA to optmize our script. LSA is a dimension reduction technique that run on the tf-idf matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Percent variance captured by all components: 99.9987853173\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Normalizer\n",
    "\n",
    "#Our SVD data reducer.  We are going to reduce the feature space from 27911 to 10.\n",
    "svd= TruncatedSVD(10)\n",
    "\n",
    "# Train the data for features since there's non tf-idf data in the features section.\n",
    "lsa = make_pipeline(svd, Normalizer(copy=False))\n",
    "# Run SVD on the training data, then project the training data.\n",
    "X_train_lsa = lsa.fit_transform(features)\n",
    "\n",
    "variance_explained=svd.explained_variance_ratio_\n",
    "total_variance = variance_explained.sum()\n",
    "print(\"Percent variance captured by all components:\",total_variance*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sentence Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f229f2e0080>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Compute document similarity using LSA components\n",
    "similarity = np.asarray(np.asmatrix(X_train_lsa) * np.asmatrix(X_train_lsa).T)\n",
    "#Only taking the first 10 sentences\n",
    "sim_matrix=pd.DataFrame(similarity,index=X_train).iloc[0:10,0:10]\n",
    "#Making a plot\n",
    "ax = sns.heatmap(sim_matrix,yticklabels=range(10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification Models \n",
    "Now, I will use supervised classification models with and without the k-means clustering predictions as features to see how well our model performs.  I will start with the default settings in the models to get a baseline score.\n",
    "## Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score with clustering: 0.17054(+/- 0.148)\n",
      "\n",
      "Training set score without clustering:0.33233(+/- 0.269)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "rfc_c = RandomForestClassifier()\n",
    "train_c = rfc_c.fit(X2_train_c, y2_train)\n",
    "rfc_c_scores = cross_val_score(rfc_c, X2_train_c, y_train, cv=5)\n",
    "print('Training set score with clustering: {:.5f}(+/- {:.3f})'.format(rfc_c_scores.mean(), rfc_c_scores.std()*2))\n",
    "\n",
    "rfc = RandomForestClassifier()\n",
    "train = rfc.fit(X2_train, y2_train)\n",
    "rfc_scores = cross_val_score(rfc, X2_train, y_train, cv=5)\n",
    "print('\\nTraining set score without clustering:{:.5f}(+/- {:.3f})'.format(rfc_scores.mean(), rfc_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the training set with the clustering feature, performed better than without it.\n",
    "\n",
    "## Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score with clustering: 0.20872(+/- 0.089)\n",
      "\n",
      "Training set score without clustering:0.29114(+/- 0.243)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n",
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "lr_c = LogisticRegression()\n",
    "train_c = lr_c.fit(X2_train_c, y2_train)\n",
    "lr_c_scores = cross_val_score(lr_c, X2_train_c, y_train, cv=5)\n",
    "print('Training set score with clustering: {:.5f}(+/- {:.3f})'.format(lr_c_scores.mean(), lr_c_scores.std()*2))\n",
    "\n",
    "lr = LogisticRegression()\n",
    "train = lr.fit(X2_train, y2_train)\n",
    "lr_scores = cross_val_score(lr, X2_train, y_train, cv=5)\n",
    "print('\\nTraining set score without clustering:{:.5f}(+/- {:.3f})'.format(lr_scores.mean(), lr_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the case of Logistic Regression, using the clustering features wasn't a good idea. However, the performance is not good in both scenarios.\n",
    "\n",
    "## Gradient Boosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set score with clustering: 0.12730(+/- 0.208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training set score without clustering:0.44971(+/- 0.259)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "clf_c = GradientBoostingClassifier()\n",
    "train_c = clf_c.fit(X2_train_c, y2_train)\n",
    "clf_c_scores = cross_val_score(clf_c, X2_train_c, y_train, cv=5)\n",
    "print('Training set score with clustering: {:.5f}(+/- {:.3f})'.format(clf_c_scores.mean(), clf_c_scores.std()*2))\n",
    "\n",
    "clf = GradientBoostingClassifier()\n",
    "train = clf.fit(X2_train, y2_train)\n",
    "clf_scores = cross_val_score(clf, X2_train, y_train, cv=5)\n",
    "print('\\nTraining set score without clustering:{:.5f}(+/- {:.3f})'.format(clf_scores.mean(), clf_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using the Gradient Boost Classifier (GBC), the performance was better without the clustering features, and the score was even better than the one obtained from the Random Forest Classifier. I will use GridSearchCV to obtain the best parameters, and try to improve GBC's accuracy.\n",
    "\n",
    "### Tuning the hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=3.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Score: 0.118421052632\n",
      "Best Parameters: {'loss': 'deviance', 'max_depth': 3, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 50, 'n_estimators': 50, 'subsample': 0.8}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Set of parameters to test for best score in Grid Search CV\n",
    "parameters = {'loss':['deviance'],\n",
    "               'min_samples_split':[50,100,200],\n",
    "             'min_samples_leaf':[1,2,4],\n",
    "             'max_depth':[3,4,5,6],\n",
    "             'max_features':['sqrt'],\n",
    "             'subsample':[0.6,0.8],\n",
    "             'n_estimators':[50,100,150]}\n",
    "\n",
    "#fitting model and printing best parameters and score from model\n",
    "grid_clf = GridSearchCV(clf, param_grid=parameters)\n",
    "grid_clf.fit(X2_train, y2_train)\n",
    "\n",
    "print('Best Score:', grid_clf.best_score_)\n",
    "best_params_clf = grid_clf.best_params_\n",
    "print('Best Parameters:', best_params_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized training set score with clustering:0.12730(+/- 0.208)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 2 members, which is too few. The minimum number of members in any class cannot be less than n_splits=5.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimized training set score without clustering:0.43433(+/- 0.245)\n"
     ]
    }
   ],
   "source": [
    "clf2 = GradientBoostingClassifier(**best_params_clf)\n",
    "train = clf2.fit(X2_train_c, y2_train)\n",
    "clf_scores_c = cross_val_score(clf, X2_train_c, y_train, cv=5)\n",
    "print('Optimized training set score with clustering:{:.5f}(+/- {:.3f})'.format(clf_scores_c.mean(), clf_scores_c.std()*2))\n",
    "train = clf2.fit(X2_train, y2_train)\n",
    "clf_scores = cross_val_score(clf, X2_train, y_train, cv=5)\n",
    "print('Optimized training set score without clustering:{:.5f}(+/- {:.3f})'.format(clf_scores.mean(), clf_scores.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test set processing and Modeling\n",
    "\n",
    "We will now apply the same approach for the test set, and test it's accuracy predicting the authors. We will be using the Gradient Boosting Classifier optimized model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Normalize Tf-idf vectors\n",
    "X_test_norm = normalize(X_test_tfidf)\n",
    "\n",
    "X_test_words = []\n",
    "\n",
    "for row in X_test:\n",
    "    # Processing each row for tokens\n",
    "    row_doc = nlp(row)\n",
    "    # Calculating length of each sentence\n",
    "    sent_len = len(row_doc) \n",
    "    # Initializing counts of different parts of speech\n",
    "    advs = 0\n",
    "    verb = 0\n",
    "    noun = 0\n",
    "    adj = 0\n",
    "    for token in row_doc:\n",
    "        # Identifying each part of speech and adding to counts\n",
    "        if token.pos_ == 'ADV':\n",
    "            advs +=1\n",
    "        elif token.pos_ == 'VERB':\n",
    "            verb +=1\n",
    "        elif token.pos_ == 'NOUN':\n",
    "            noun +=1\n",
    "        elif token.pos_ == 'ADJ':\n",
    "            adj +=1\n",
    "    # Creating a list of all features for each sentence\n",
    "    X_test_words.append([row_doc, advs, verb, noun, adj, sent_len])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Re-indexing y_test\n",
    "y_test_new = y_test.reset_index(drop=True)\n",
    "\n",
    "# Data frame for features\n",
    "txt_bow_test = pd.DataFrame(data=X_test_words, columns=['BOW', 'ADV', 'VERB', 'NOUN', 'ADJ', 'sent_length'])\n",
    "\n",
    "# Adding in year data\n",
    "txt_bow_test = pd.concat([txt_bow_test, y_test_new], ignore_index=False, axis=1)\n",
    "\n",
    "# Combining features into one data frame\n",
    "X_test_norm_df = pd.DataFrame(data=X_test_norm.toarray())\n",
    "txt_tfidf_bow_test = pd.concat([txt_bow_test, X_test_norm_df], ignore_index=False, axis=1)\n",
    "txt_tfidf_bow_test.head()\n",
    "\n",
    "# Identifying features and labels to choose from\n",
    "features_test = txt_tfidf_bow_test.drop(['BOW', 'author'], axis=1)\n",
    "y2_test = txt_tfidf_bow_test.author"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Instantiating and fitting the 150 best features\n",
    "X2_test = SelectKBest(chi2, k=150).fit_transform(features_test, y2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>col_0</th>\n",
       "      <th>0</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>author</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>aristotle</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dickens</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>doyle</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>emerson</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>hawthorne</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>irving</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>jefferson</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>kant</th>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>plato</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>poe</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>shakespeare</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "col_0        0  2  3  4\n",
       "author                 \n",
       "aristotle    0  3  0  0\n",
       "dickens      1  0  0  0\n",
       "doyle        1  1  0  0\n",
       "emerson      0  2  0  1\n",
       "hawthorne    1  0  0  1\n",
       "irving       1  2  0  0\n",
       "jefferson    0  0  0  3\n",
       "kant         2  0  0  0\n",
       "plato        0  1  0  0\n",
       "poe          0  1  0  1\n",
       "shakespeare  2  1  1  0"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Calulate predicted values\n",
    "\n",
    "y_pred_test = kmeans.predict(X2_test)\n",
    "\n",
    "pd.crosstab(y2_test, y_pred_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Silhouette Score: 0.4658696\n"
     ]
    }
   ],
   "source": [
    "print('Silhouette Score: {:0.7}'.format(silhouette_score(X2_test, y_pred_test, metric='euclidean')))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This Silhouette Score is better than what I expected."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X2_test_c = pd.DataFrame(X2_test)\n",
    "X2_test_c['kmeans_clust'] = y_pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mache/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_split.py:605: Warning: The least populated class in y has only 1 members, which is too few. The minimum number of members in any class cannot be less than n_splits=2.\n",
      "  % (min_groups, self.n_splits)), Warning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test set score: 0.16250(+/- 0.075)\n"
     ]
    }
   ],
   "source": [
    "clf_c2_scores_test = cross_val_score(clf2, X2_test_c, y_test, cv=2)\n",
    "print('Test set score: {:.5f}(+/- {:.3f})'.format(clf_c2_scores_test.mean(), clf_c2_scores_test.std()*2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Though the Silhouette Score was good, the accuracy predicting the authors wasn't good at all.\n",
    "\n",
    "## Conclusion\n",
    "\n",
    "Gradient Boost Classifier with the dataset containing the clusters as features improved, the model's performance, over the other tested model's, however, it's accuracy was far from great.\n",
    "\n",
    "I think the reason for this poor performance is due to the fact that we didn't use the whole books as part of the texts for each author, and just used some portions of it to save computational resources and time. Clustering the data did help in improving the performance of the training set, however, the overall accuracy is below 50 %, and I think this is due to the problem described earlier.\n",
    "\n",
    "For optimizing it's performance, I would start increasing the size of the texts for each author, and I think we could get much better results. I also believe that clustering by author was a good idea, given the singularity between each of them and I would still persue this approach."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
